{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-23 14:05:47.361179: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-23 14:05:47.518317: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-23 14:05:47.518335: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-23 14:05:47.546679: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-23 14:05:48.172633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-23 14:05:48.172716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-23 14:05:48.172724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "# Suppress TensorFlow logs\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Suppress logging messages\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>CPU utilization@util</th>\n",
       "      <th>CPU load@load1</th>\n",
       "      <th>CPU load@load5</th>\n",
       "      <th>CPU load@load15</th>\n",
       "      <th>Memory@mem_used_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03-11-2023 00:00</td>\n",
       "      <td>28.77810</td>\n",
       "      <td>4.01800</td>\n",
       "      <td>2.98250</td>\n",
       "      <td>2.28150</td>\n",
       "      <td>83.8479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-11-2023 06:00</td>\n",
       "      <td>90.73230</td>\n",
       "      <td>76.23300</td>\n",
       "      <td>63.69200</td>\n",
       "      <td>42.43170</td>\n",
       "      <td>89.8218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03-11-2023 12:00</td>\n",
       "      <td>91.62920</td>\n",
       "      <td>74.75800</td>\n",
       "      <td>68.16150</td>\n",
       "      <td>59.83700</td>\n",
       "      <td>65.2126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03-11-2023 18:00</td>\n",
       "      <td>8.54688</td>\n",
       "      <td>2.74917</td>\n",
       "      <td>2.01867</td>\n",
       "      <td>1.51000</td>\n",
       "      <td>52.2027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04-11-2023 00:00</td>\n",
       "      <td>9.33542</td>\n",
       "      <td>2.62667</td>\n",
       "      <td>1.87300</td>\n",
       "      <td>1.43283</td>\n",
       "      <td>52.2296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7503</th>\n",
       "      <td>30-12-2027 18:00</td>\n",
       "      <td>28.95000</td>\n",
       "      <td>6.13500</td>\n",
       "      <td>4.94917</td>\n",
       "      <td>4.65900</td>\n",
       "      <td>88.5298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7504</th>\n",
       "      <td>31-12-2027 00:00</td>\n",
       "      <td>18.52500</td>\n",
       "      <td>3.48567</td>\n",
       "      <td>2.18283</td>\n",
       "      <td>1.26583</td>\n",
       "      <td>93.5433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>31-12-2027 06:00</td>\n",
       "      <td>60.16670</td>\n",
       "      <td>13.79480</td>\n",
       "      <td>11.81680</td>\n",
       "      <td>9.61400</td>\n",
       "      <td>95.5605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>31-12-2027 12:00</td>\n",
       "      <td>31.49370</td>\n",
       "      <td>6.56550</td>\n",
       "      <td>5.33067</td>\n",
       "      <td>4.91767</td>\n",
       "      <td>73.6354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7507</th>\n",
       "      <td>31-12-2027 18:00</td>\n",
       "      <td>27.85420</td>\n",
       "      <td>7.19083</td>\n",
       "      <td>5.62300</td>\n",
       "      <td>5.01600</td>\n",
       "      <td>75.0574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7508 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  CPU utilization@util  CPU load@load1  CPU load@load5  \\\n",
       "0     03-11-2023 00:00              28.77810         4.01800         2.98250   \n",
       "1     03-11-2023 06:00              90.73230        76.23300        63.69200   \n",
       "2     03-11-2023 12:00              91.62920        74.75800        68.16150   \n",
       "3     03-11-2023 18:00               8.54688         2.74917         2.01867   \n",
       "4     04-11-2023 00:00               9.33542         2.62667         1.87300   \n",
       "...                ...                   ...             ...             ...   \n",
       "7503  30-12-2027 18:00              28.95000         6.13500         4.94917   \n",
       "7504  31-12-2027 00:00              18.52500         3.48567         2.18283   \n",
       "7505  31-12-2027 06:00              60.16670        13.79480        11.81680   \n",
       "7506  31-12-2027 12:00              31.49370         6.56550         5.33067   \n",
       "7507  31-12-2027 18:00              27.85420         7.19083         5.62300   \n",
       "\n",
       "      CPU load@load15  Memory@mem_used_percent  \n",
       "0             2.28150                  83.8479  \n",
       "1            42.43170                  89.8218  \n",
       "2            59.83700                  65.2126  \n",
       "3             1.51000                  52.2027  \n",
       "4             1.43283                  52.2296  \n",
       "...               ...                      ...  \n",
       "7503          4.65900                  88.5298  \n",
       "7504          1.26583                  93.5433  \n",
       "7505          9.61400                  95.5605  \n",
       "7506          4.91767                  73.6354  \n",
       "7507          5.01600                  75.0574  \n",
       "\n",
       "[7508 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    " \n",
    "# Load data\n",
    "# df = pd.read_csv(\"/content/dqp_edge_metric_data_till_31_12_2027.csv\")\n",
    "df = pd.read_csv(\"dataset/dqp_edge_metric_data_till_31_12_2027.csv\")\n",
    "df = df.dropna()\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "# Prepare data for multiple outputs\n",
    "columns_to_predict = ['CPU load@load1', 'CPU load@load5', 'CPU load@load15', 'CPU utilization@util', 'Memory@mem_used_percent']\n",
    "timeseries_data = df[columns_to_predict].values\n",
    " \n",
    "# Prepare data function\n",
    "def prepare_data(timeseries_data, n_features):\n",
    "    X, y = [], []\n",
    "    for i in range(len(timeseries_data)):\n",
    "        end_ix = i + n_features\n",
    "        if end_ix > len(timeseries_data)-1:\n",
    "            break\n",
    "        seq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    " \n",
    "# Define input sequence\n",
    "n_steps = 3\n",
    "X, y = prepare_data(timeseries_data, n_steps)\n",
    " \n",
    "# Reshape input data\n",
    "n_features = len(columns_to_predict)\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    " \n",
    "# Define model architecture for multiple outputs\n",
    "model = Sequential()\n",
    "model.add(LSTM(500, return_sequences=True, activation='relu', input_shape=(n_steps, n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(500, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(500, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(150, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(50, activation='relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(len(columns_to_predict)))  # Output layer with multiple neurons corresponding to each output column\n",
    " \n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    " \n",
    "# Fit model\n",
    "model.fit(X, y, epochs=150)\n",
    " \n",
    "# Future prediction\n",
    "future_steps = 150  # Number of steps to predict into the future\n",
    "x_input = timeseries_data[-n_steps:]  # Use the last n_steps as input\n",
    " \n",
    "predictions = []\n",
    "for _ in range(future_steps):\n",
    "    x_input = x_input.reshape((1, n_steps, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    predictions.append(yhat[0])\n",
    "    x_input = np.concatenate([x_input[:, 1:, :], yhat.reshape((1, 1, n_features))], axis=1)\n",
    " \n",
    "# Inverse transform the predictions (if needed)\n",
    "# scaler.inverse_transform(predictions)\n",
    " \n",
    "# Print future predictions\n",
    "print(\"Future Predictions:\")\n",
    "print(predictions)\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Number of data points in the original dataset\n",
    "num_data_points = len(df)\n",
    " \n",
    "# Generate time indices for future predictions\n",
    "future_time_indices = np.arange(num_data_points, num_data_points + future_steps)\n",
    " \n",
    "# Plot future predictions separately for each metric\n",
    "fig, axs = plt.subplots(len(columns_to_predict), 1, figsize=(10, 6*len(columns_to_predict)))\n",
    " \n",
    "for i, column in enumerate(columns_to_predict):\n",
    "    # Plot real values\n",
    "    axs[i].plot(df.index, df[column], label='Real Values', color='blue')\n",
    "    # Plot predicted values\n",
    "    axs[i].plot(future_time_indices, [prediction[i] for prediction in predictions], label='Predicted Values', color='orange')\n",
    "    axs[i].set_xlabel('Time Index')\n",
    "    axs[i].set_ylabel(column)\n",
    "    axs[i].legend()\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DataCleaning class\n",
    "class DataCleaning(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Prepare data for multiple outputs\n",
    "        self.columns_to_predict = ['CPU load@load1', 'CPU load@load5', 'CPU load@load15', 'CPU utilization@util', \n",
    "                                    'Memory@mem_used_percent']\n",
    "        self.n_features = 8\n",
    "        \n",
    "    # Prepare data function\n",
    "    def prepare_data(self, timeseries_data, n_features):\n",
    "        print('Data is preparing...')\n",
    "        X, y = [], []\n",
    "        for i in range(len(timeseries_data)):\n",
    "            end_ix = i + n_features\n",
    "            if end_ix > len(timeseries_data) - 1:\n",
    "                break\n",
    "            seq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
    "            X.append(seq_x)\n",
    "            y.append(seq_y)\n",
    "        \n",
    "        print('Data preparing done...')\n",
    "        \n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    # Define a function to create the LSTM model\n",
    "    def create_lstm_model(self, units=50, optimizer='adam', hidden_layers=1, hidden_units=50,\n",
    "                        dropout_rate=0.2, input_shape=(8, 5), learning_rate=0.001):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units, return_sequences=True, activation='relu', input_shape=input_shape))\n",
    "        model.add(LSTM(units, activation='relu'))\n",
    "        \n",
    "        # Add hidden layers with dropout and batch normalization\n",
    "        for _ in range(hidden_layers):\n",
    "            model.add(Dense(hidden_units, activation='relu'))\n",
    "            model.add(Dropout(dropout_rate))\n",
    "            model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Dense(len(self.columns_to_predict)))\n",
    "        \n",
    "        if optimizer == 'adam':\n",
    "            opt = Adam(learning_rate=learning_rate)\n",
    "        else:\n",
    "            opt = RMSprop(learning_rate=learning_rate)\n",
    "        \n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "        return model\n",
    "\n",
    "    # def create_lstm_model(units=70, optimizer='adam', hidden_layers=0, hidden_units=70):\n",
    "    #     # Define model architecture for multiple outputs\n",
    "    #     model = Sequential()\n",
    "    #     model.add(LSTM(units,return_sequences=True, activation='relu',input_shape=(X.shape[1], X.shape[2])))\n",
    "    #     model.add(LSTM(units, activation='relu',return_sequences=True))\n",
    "    #     model.add(LSTM(units, activation='relu',return_sequences=True))\n",
    "    #     model.add(LSTM(units, activation='relu'))\n",
    "\n",
    "    #     # Add hidden layers\n",
    "    #     for _ in range(hidden_layers):\n",
    "    #         model.add(Dense(hidden_units, activation='relu'))\n",
    "\n",
    "    #     model.add(Dense(len(columns_to_predict)))\n",
    "    #     model.compile(loss='mse', optimizer=optimizer)\n",
    "    #     return model\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Reshape input data\n",
    "        n_features = len(self.columns_to_predict)\n",
    "        X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(units=70, optimizer='adam', hidden_layers=0, hidden_units=70):\n",
    "            # Define model architecture for multiple outputs\n",
    "            model = Sequential()\n",
    "            model.add(LSTM(units,return_sequences=True, activation='relu',input_shape=(X.shape[1], X.shape[2])))\n",
    "            model.add(LSTM(units, activation='relu',return_sequences=True))\n",
    "            model.add(LSTM(units, activation='relu',return_sequences=True))\n",
    "            model.add(LSTM(units, activation='relu'))\n",
    "\n",
    "            # Add hidden layers\n",
    "            for _ in range(hidden_layers):\n",
    "                model.add(Dense(hidden_units, activation='relu'))\n",
    "\n",
    "            model.add(Dense(len(columns_to_predict)))\n",
    "            model.compile(loss='mse', optimizer=optimizer)\n",
    "            return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 8\n",
    "    \n",
    "def cleaning(timeseries_data):\n",
    "    data_cleaning_obj = DataCleaning()\n",
    "    X,y = data_cleaning_obj.prepare_data(timeseries_data, n_steps)\n",
    "    return X,y \n",
    "\n",
    "@st.cache\n",
    "def future_prediction(df,best_model_lr,timeseries_data):\n",
    "    # Future prediction\n",
    "    n_features = 5\n",
    "    future_steps = 500  # Number of steps to predict into the future\n",
    "    x_input = timeseries_data[-n_steps:]  # Use the last n_steps as input\n",
    "    \n",
    "    predictions = []\n",
    "    for _ in range(future_steps):\n",
    "        x_input = x_input.reshape((1, n_steps, n_features))\n",
    "        yhat = best_model_lr.predict(x_input)\n",
    "        predictions.append(yhat)\n",
    "        x_input = np.concatenate([x_input[:, 1:, :], yhat.reshape((1, 1, n_features))], axis=1)\n",
    "    \n",
    "    # Number of data points in the original dataset\n",
    "    num_data_points = len(df)\n",
    "    \n",
    "    # Generate time indices for future predictions\n",
    "    future_time_indices = np.arange(num_data_points, num_data_points + future_steps)\n",
    "\n",
    "    return predictions,future_time_indices\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
